---
title: "Sugest√µes de melhorias e coment√°rios"
subtitle: "MEDIDAS DE DIAGN√ìSTICO EM MODELOS DE REGRESS√ÉO BETA PRIME"
date: "23/08/2023 as 14h00"
lang: pt
author: "Prof. Dr. Pedro Rafael D. Marinho"
format: html
code-tools: true
code-copy: true
number-sections: true
page-layout: full
editor: source
---

# Objetivos principais e observa√ß√µes:

Os objetivos principais do trabalho s√£o:

1. Estudo dos res√≠duos do modelo de regress√£o beta prime, para al√©m do que Bourguignon et al. (2021) considerou.

2. Bourguignon et al. (2021) considerou os res√≠duo quant√≠lico e do de Pearson;

3. Aqui foram considerados os res√≠duo:
  + res√≠duos ponderado;
  + **ponderado padronizado**. Esse foi o res√≠duo proposto;
  + Pearson padronizado;
  + Foi proposto coeficiente de predi√ß√£o $P^2$.

4. Avalia-se a distribui√ß√£o emp√≠rica dos
res√≠duos em diferentes cen√°rios do modelo de regress√£o BP e comparamos seus desempenhos
para detectar especifica√ß√£o incorreta.

5. A distribui√ß√£o beta prime pode ser escrita na fam√≠lia exponencial de distribui√ß√µes. Portanto, "compete" com os modelos lineares generalizados.

7. Densidade da Beta Prime


$$f(y;\alpha, \beta) = \frac{y^{\alpha - 1}(1 + y)^{-(\alpha + \beta)}}{B(\alpha, \beta)}, y \geq 0,$$
com $\alpha > 0$ e  $\beta > 0$.

8. Nota√ß√µes:

+ $r_i^Q$: res√≠duo quant√≠lico;
+ $r_i^P$: res√≠duo de Pearson;
+ $r^{\beta}$: res√≠duo poderado;
+ $r^{\beta*}$: res√≠duo ponderado padronizado;
+ $r^{P *}$: res√≠duo de Pearson padronizado.

# Seguest√µes e coment√°rios

## O que √© definir os res√≠duos ponderado e Pearson padronizado?

No resumo voc√™ diz: 

> "al√©m do res√≠duo quant√≠lico e do
res√≠duo de Pearson utilizados por Bourguignon et al. (2021), **definimos** os res√≠duos ponderado,
ponderado padronizado (ESPINHEIRA et al., 2008) e Pearson padronizado (MCCULLAGH;
NELDER, 1989) para tal modelo." -- Maria Eduarda

O que √© definir os res√≠udos? N√£o seria melhor trocar definir por "avaliamos"? Eles n√£o j√° foram definidos pelos autores de uma forma gen√©rica? Definir tem conota√ß√£o de que voc√™s criaram.

## Suporte da distribui√ß√£o BP

O suporte da distribui√ß√£o da beta prime n√£o inclue o zero ($y \geq 0$)? Sei que Bourguignon et al. (2021) definiu como $y > 0$, mas n√£o seria $y \geq 0$? Note que na p√°gina 34 do paper (p√°gina 2 do PDF), √∫ltimo par√°grafo, ele diz:

> Pode-se provar que a fun√ß√£o densidade BP est√° diminuindo com $f(y|\alpha,\beta)$, se $0 < \alpha < 1$ com moda em $y = 0$. - Bourguignon et al. (2021)

Al√©m disso, nas refer√™ncias da distribui√ß√£o $y\geq 0$.

**Uma observa√ß√£o**: Ela tamb√©m √© conhecida como distribui√ß√£o de Pearson tipo VI. üéÅ

<!-- ## Estudar se a distribui√ß√£o normal √© uma boa aproxima√ß√£o? -->

<!-- No trabalho voc√™s estudam se a distribui√ß√£o normal-padr√£o √© uma boa aproxima√ß√£o para os res√≠duos.  -->

<!-- > "Em particular, objetivamos verificar se a distribui√ß√£o normal -->
<!-- padr√£o √© uma boa aproxima√ß√£o para a distribui√ß√£o emp√≠rica desses cinco res√≠duos, quando o -->
<!-- modelo de regress√£o BP √© corretamente especificado, e analisar seus desempenhos para detectar -->
<!-- erros de especifica√ß√£o." -- Maria Eduarda -->

<!-- Isso j√° n√£o seria esperado pelo Teorema Central do Limite - TCL? Se eu tenho uma sequ√™ncia de vari√°veis aleat√≥rias i.i.d's, n√£o √© esperado se tenho dados suficientes, terei uma boa aproxima√ß√£o? Por que simular isso se eu tenho garantias te√≥ricas da boa aproxima√ß√£o? -->


## Utilizar a teoria da informa√ß√£o

A ideia do estudo √© a avalia√ß√£o dos res√≠duos para a an√°lise da especifica√ß√£o do modelo de regress√£o beta prime. Portanto, queremos estimar $r({\bf x}) = \mathbb{E}(Y|X)$, ou seja, desejamos uma fun√ß√£o de regress√£o com boa capacidade preditiva. Uma das suposi√µes √© que $Y\sim BP$. 

Pergunta: em cen√°rios em que $Y$ segue a distribui√ß√£o aproximadamente BP, utilizar estat√≠sticas de adequa√ß√£o de ajuste para comparar a regress√£o BP com outros modelos de regress√£o, a exemplo, dos MGL's, como, por exemplo, com o modelo MLG com $Y \sim Gama$, a an√°lise de res√≠duos proposta n√£o levam as mesmas conclus√µes de que chegar√≠amos em aplicar utilizar a teoria da informa√ß√£o para checar a qualidade do ajuste? Por exemplo, utilizar estat√≠sticas como a estat√≠stica de Cram√©r-von Mises e Anderson-Darling para modelos n√£o encaixados n√£o poderia ser √∫til para comparar a distribui√ß√£o de $Y$ e decidir qual modelo melhor se ajusta aos dados? 

## Especifica√ß√£o correta garante boa capacidade preditiva?

A especifica√ß√£o adequada do modelo garante boa capacidade preditiva? No resumo voc√™ diz:

> "Para isso, √© importante utilizar res√≠duos com propriedades
conhecidas e que apresentem bom desempenho." - Maria Eduarda


Segundo a l√≥gica de aprendizagem de m√°quina n√£o! Ver o paper do Leio Breiman:

> [Breiman, L. (2001a). Statistical modeling: The two cultures. Statistical Science, 16(3), 199‚Äì231](https://projecteuclid.org/journalArticle/Download?urlId=10.1214%2Fss%2F1009213726)

Nesse artigo ele estabelece duas culturas na modelagem estat√≠stica:

1. **Data modeling culture**: nela, em geral, se assume que o modelo de regress√£o utilizado $r({\bf x}) = \mathbb{E}(Y|{\bf X})$ √© correto. O principal objetivo dessa abordagem √© a interpreta√ß√£o dos par√¢metros que indexam o modelo $r({\bf x})$.

2. **Algorithmic modeling culture**: essa √© a cultura que domina a comunidade de aprendizagem de m√°quina. Nessa abordagem, o principal objetivo s√£o as predi√ß√µes por meio de novas observa√ß√µes. N√£o se assume que o modelo utilizado √© o modelo correto. Nesse tipo de modelagem, muitas vezes os algoritmos n√£o envolve nenhuma estrutura probabil√≠stica. Muitas vezes, modelos n√£o bem especificado conduzem a boas predi√ß√µes.

Existe uma sequ√™ncia de respostas √† esse paper, por exemplo, estat√≠sticos renomados como o David Cox e o Bradley Efron respondem positivamente √† esse paper. O artigo possui mais de 5300 cita√ß√µes.


Podemos ter modelos que n√£o est√£o bem especificados, mas possuem boa performance preditiva. Por exemplo, tente ajustar um [random forest](https://hastie.su.domains/ISLR2/ISLRv2_corrected_June_2023.pdf) em um problema, mesmo $Y \in B(\alpha,\beta)$, em um grande conjunto de dados, e usando um conjunto de teste, calcule o erro quadr√°tico m√©dio observado na amostra independente. Muito provavelmente o *random forest* ter√° uma capacidade preditiva igual ou superior ao modelo de regress√£o BP.

Dessa forma, sugiro voc√™ comentar um pouco mais qual a grande import√¢ncia da boa especifica√ß√£o do modelo. Essa boa especifica√ß√£o n√£o est√° √∫nica e exclusivamente na capacidade preditiva do modelo, pois muitas vezes poderemos nos surpreender com modelos n√£o muito bem especificado e que performa muito melhor. A grande contribui√ß√£o de termos um modelo que esteja bem especificado √© permitir que an√°lises interpretativas possam ser realizadas. √â preciso destacar isso, uma vez que muitas pessoas que est√£o lendo materiais da estat√≠stica s√£o pessoas da ci√™ncia de dados/computa√ß√£o, em que muitas dalas "pregam" que o interesse est√° na previs√£o e ofuscam a import√¢ncia de ter modelos bem especificados quando desejamos perceber a rela√ß√£o entre as vari√°veis, construir intervalos para os par√¢metros e testar hip√≥teses.

No material fica um pouco nebuloso de qual a grande ideia de se fazer uma an√°lise de res√≠duos.

## Avaliamos a distribui√ß√£o emp√≠rica dos res√≠duos

Voc√™s fazem uma an√°lise de distribui√ß√£o emp√≠rica do res√≠duo, para detec√ß√£o da especifica√ß√£o incorreta do modelo de regress√£o BP. Existe um apelo frequentista, uma vez que necessita-se de uma aproxima√ß√£o assint√≥tica da distribui√ß√£o dos res√≠duos para a normal. At√© que ponto, essa an√°lise √© melhor que utilizar a teoria da informa√ß√£o e estudar a distribui√ß√£o de $Y$, sobretudo em situa√ß√µes em que temos poucos dados ou uma quantidade moderada de dados?

## Pensam em adicionar penaliza√ß√£o?

Sei que voc√™s focaram em desenvolver infer√™ncia para auxiliar a an√°lise de especifica√ß√£o do modelo de regress√£o BP. Por√©m, voc√™s pensaram dar passos para avan√ßar o modelo de regress√£o BP, por exemplo, pensam em adicionar algum tipo de penaliza√ß√£o no modelo de regress√£o beta prime? Existe um *trade off* entre vi√©s e vari√¢ncia, em que uma penaliza√ß√£o poderia fazer com que o modelo viesse performar melhor. Um estudo avaliando a peformance do modelo com e sem penaliza√ß√£o, em diversos cen√°rios poderia ser interessante.

## A vari√¢ncia do modelo de regress√£o BP √© maior? Como assim?

Voc√™ diz:

> "Uma das vantagens refere-se √† modelagem de dados mais dispersos, uma vez que a vari√¢ncia do
modelo de regress√£o BP √© maior que a vari√¢ncia do modelo gama." - Maria Eduarda, p√°gina 12

Voc√™ refere-se √† vari√¢ncia do modelo ou a capacidade do modelo em modelar $Y$ com maior vari√¢ncia? O risco preditivo do modelo n√£o sofre com modelos com maior vari√¢ncia? Veja que o risco preditivo $R(\widehat{g})$, usando a norma $L_2$ no risco preditivo de um modelo de regress√£o, temos que o risco poder√° ser decomposto como:

$$R(\widehat{g}) = \mathbb{E}\left[(Y - \widehat{g}({\bf X}))^2| {\bf X} = {\bf x}\right] = \underbrace{\mathbb{V}[Y | {\bf X = x}]}_{\mathrm{i - Vari√¢ncia\,\, intr√≠nseca}} + \overbrace{(r({\bf x}) - \mathbb{E}[\widehat{g}({\bf x})])^2}^{\mathrm{ii - Vi√©s\, ao\, quadrado\, do\, modelo}} + \underbrace{\mathbb{V}[\widehat{g}({\bf x})]}_{\mathrm{iii - Vari√¢ncia\, do\, modelo}},$$ 

em que $\widehat{g}(\cdot)$ √© sua fun√ß√£o de regress√£o estimada. Quando voc√™ diz que a vari√¢ncia do modelo de regress√£o BP √© maior, voc√™ n√£o est√° dizendo que iii √© maior? Isso n√£o me daria um maior risco preditivo? Escreva melhor o que voc√™ est√° querendo dizer com vari√¢ncia maior!

Muito provavelmente existem diversas sequ√™ncias de observa√ß√µes de $Y$ em que poderiam ser bem modeladas pela distribui√ß√£o Gama e tamb√©m pela distribui√ß√£o BP. Se o modelo de regress√£o BP tem vari√¢ncia maior, poderia entender que modelar por um MLG eu teria um modelo que performa melhor? Como foi verificado que a vari√¢ncia do modelo √© maior! Isso √© realmente algo bom?

Voc√™ n√£o estaria querendo dizer que o modelo de regress√£o BP modela dados mais dispersos? Isso pode ser diferente de um modelo com vari√¢ncia maior.


## O que √© precis√£o dos dados?

> Por outro lado, o res√≠duo ponderado padronizado aqui proposto dever√° ser
utilizado com cautela, dado que os experimentos de Monte Carlo revelaram que a proximidade
da sua distribui√ß√£o emp√≠rica pela distribui√ß√£o normal padr√£o depende da precis√£o dos dados
ajustados pelo modelo de regress√£o BP. - Maria Eduarda, p√°gina 41, primeira linha.

**Precis√£o dos dados? Essa express√£o √© estranha!**

O que tem que ser preciso s√£o os modelos. Acho que voc√™ se refere √† converg√™ncia assint√≥tica das estimativas dos erros, nesse caso, do estimador do res√≠duo ponderado padronizado, denotado no trabalho por $r_i^{\beta^*}$ para a distribui√ß√£o normal. Da√≠, quando $n \rightarrow +\infty$ temos que pela Teorema Central do Limite, $r_i^{\beta^*}$ deve convergir em distribui√ß√£o para a distribui√ß√£o normal. **Precis√£o de dados** tem outra conota√ß√£o!

## Em qual situa√ß√£o $r_i^{\beta *}$ √© melhor que $r_i^{Q}$

Em que situa√ß√£o os res√≠duos propostos (res√≠duo ponderado padronizado) √© melhor que utilizar o $r_i^{Q}$? Ao fim, existe alguma situa√ß√£o que eu devo utilizar $r_i^{\beta *}$?

## Na avalia√ß√£o das estat√≠sticas PRESS

[PRESS - Soma dos Quadrados dos Erros de Previs√£o](https://sci-hub.se/https://www.tandfonline.com/doi/abs/10.1080/00401706.1974.10489157)

Para avaliar a capacidade preditiva do modelo, √© preciso que a sequ√™ncia de vari√°veis aleat√≥rias $(Y_i - \widehat{Y}_i)^2$ sejam i.i.d's, de modo que se voc√™ utiliza a mesma amostra para ajustar o modelo e obter $\widehat{Y}$ tamb√©m para avaliar $d_1^2 = (Y_1 - \widehat{Y}_1)^2, d_2^2 = (Y_2 - \widehat{Y}_2)^2, \cdots, d_m^2 = (Y_m - \widehat{Y}_m)^2$, fazem com que essa sequ√™ncia n√£o sejam independentes. √â preciso ter $m$ novas observa√ß√µes que n√£o foram utilizadas para ajustar o modelo. N√£o tendo independ√™ncia, n√£o h√° garantias da lei dos grandes n√∫meros para que

$$PRESS \rightarrow \mathbb{E}[(Y - \widehat{Y})^2] = n \times EQM$$

Em outras palavras, se foram utilizados as mesmas observa√ß√µes para calcular $\widehat{y}_i$, para todo $i$, ent√£o a sequ√™ncia $(y_i - \widehat{y}_i)^2$ n√£o s√£o observa√ß√µes de uma sequ√™ncia de vari√°veis aleat√≥rias independentes, e a aproxima√ß√£o acima n√£o √© verdadeira. Essa separa√ß√£o de um conjunto de novas observa√ß√µes √© feita em todo procedimento de valida√ß√£o cruzada, como no caso mais geral que √© o *leave-one-out cross-validation*. 

Muitas observa√ß√µes, a saber $n - 1$, s√£o utilizadas para calcular $\widehat{y}_i$, para todo $i = 1, \cdots, n$. Portanto, existe depend√™ncia entre a sequ√™ncia $d_1^2, \cdots, d_n^2$. O interessante seria considerar $m$ novas observa√ß√µes, e calcular $d_{n + 1}^2, \cdots, d_{m}^2$. √â por isso, que muitos algoritmos de aprendizagem de m√°quina utilizam um conjunto de teste independente dos dados que s√£o utilizados para ajustar os modelos.

## P√°gina 47 $e_{(i)}$

N√£o seria melhor trocar $e_{(i)} = y_i - \widehat{y}_{(-i)}$ por $r_{(i)}$? O $e_{(i)}$ me induz a pensar no erro que √© o que desejamos estimar.

## Ainda sobre a independ√™ncia

O artigo do [Mediavilla](http://www.na-businesspress.com/JABE/MendezWeb.pdf) n√£o √© um paper com muitos cuidados. N√£o √© verdade que a sequ√™ncia de observa√ß√µes s√£o independentes.

Na p√°gina 48 voc√™ diz:

> Como a $i$-√©sima observa√ß√£o √© omitida para prever $y_i$, ent√£o $\widehat{y}_{(-i)}$ e $e_{(-i)}$ s√£o independentes, o que garante que a estat√≠stica $PRESS$ seja uma medida indicativa da capacidade de
previs√£o de um modelo de regress√£o, independentemente da qualidade do ajuste do modelo
(MEDIAVILLA et al., 2008).

Insisto que essa sequ√™ncia n√£o s√£o de observa√ß√µes de vari√°veis aleat√≥rias independentes. Clique [AQUI](https://pedro-rafael.shinyapps.io/shiny_apps/#section-avalia%C3%A7%C3%A3o-do-risco-preditivo) em que criei uma aplica√ß√£o Web em que avalio o risco preditivo usando um precedimento de *leave-one-out cross-validation*, para uma regress√£o polinomial. Chamo de "certo" o risco quando avaliado em um conjunto de dados independente, em que nenhuma observa√ß√£o foi utilizada para calcular $\widehat{y}_i$ e chamo de "errado" o procedimento de realizar o *leave-one-out cross-validation* e depois n√£o reavaliar o melhor modelo em um conjunto de dados independente. Note que, da forma errada, apenas selecionado o modelo usando*leave-one-out cross-validation* sem considerar um conjunto de teste me conduz a ideia de que aumentar o grau do polin√¥mio, i.e., introduzir mais par√¢metros sempre ser√° uma boa altarnativa. Isso n√£o √© verdade, uma vez que um polin√¥mio com grau muito elevado me leva √† *overfitting*.

## AIC

Por que voc√™s n√£o compararam a performance da adequa√ß√£o de ajuste do modelo usando o AIC? O procedimento de **Leave-one-out cross-validation** ao qual se baseia a estat√≠stica $PRESS$ (ver Allen 1974), em que

$$PRESS = \sum_{i = 1}^n (Y - \widehat{Y}_{(i)})^2.$$
S√≥ que Stones, um pouco depois, em 1977, mostro que **Leave-one-out cross-validation** converge assintoticamente para o m√©todo AIC. Voc√™s possuem a estrutura probabil√≠stica do modelo que permite o c√°lculo anal√≠tico do AIC. Portanto, avaliar o risco preditivo usando o AIC j√° seria suficiente, i.e, seria o melhor resultado assint√≥tico do **leave-one-out**. Leia o artigo [An Asymptotic Equivalence of Choice of Models by Cross-validation and Akaike's Criterion](https://www.jstor.org/stable/2984877). Esse paper √© citado em mais de 1500 trabalhos.

Sugiro que seja comparado tamb√©m com o AIC, uma vez que isso √© facilmente feito.


## Como se comportam as estat√≠sticas $P_{\beta}^2$ e $P_{\beta_c}^2$

Na p√°gina 49 voc√™ define as estat√≠sticas $P_{\beta}^2$ e $P_{\beta_c}^2$. Como se comportam tais estat√≠sticas na presen√ßa de mais covari√°veis no modelo? S√£o mon√≥tonas? Seria legal ter uma simula√ß√£o de Monte-Carlo mostrando como se comportam tais estat√≠sticas e se elas penalizam modelos com muitos par√¢metros. Fazer um gr√°fico com a evolu√ß√£o das estat√≠sticas em que no eixo $x$ voc√™ vai aumentando a quantidade de par√¢metros seria uma forma boa de visualizar o comportamento. A ideia √© que as estat√≠sticas $P_{\beta}^2$ e $P_{\beta_c}^2$ decres√ßam e a partir de um momento come√ßem a piorar na medida que aumenta-se a quantidade de covari√°veis. 

Veja essa aplica√ß√£o que implementei  a estat√≠stica $P^2$ para um modelo de regress√£o polinomial. Note que ela sinaliza que colocar mais par√¢metros sempre √© uma boa op√ß√£o!

Clique [**AQUI**](https://pedro-rafael.shinyapps.io/shiny_apps/#section-maria-eduarda) para ver.

A estat√≠stica $P_{\beta_c}^2$ sofre com isso? Seria legal fazer um gr√°fico mostrando qual o comportamento dela quando se adiciona mais covari√°veis no modelo.

## Cad√™ os demais c√≥digos?

No c√≥digo das simula√ß√µes h√° diversas inter√ß√µes de c√≥digos R com o a fun√ß√£o `source()`. Onde est√£o esses arquivos. Sugiro criar uma conta no [GitHub](https://github.com/) e criar um reposit√≥rio com o script R e um pequeno coment√°rio do que cada c√≥digo faz.

  + Onde est√° `gamlss_BP.R`?
  + Onde est√° `glmBP.R`?
  + Onde est√° `Estimation.R`?
  + Onde est√° `Residual_H_Log_Like_BP.R`?
  
Por exemplo, no paper do Marcelo, ele coloca a refer√™ncia para o reposit√≥rio do GitHub em que cont√©m o pacote **BPmodel** ([ver aqui](https://github.com/santosneto/BPmodel)) que muito provavelmente voc√™ est√° usando em algum script. 
  
√â preciso que seu experimento seja totalmente repoduz√≠vel. Quem ler quer chegar aos mesmos resultados!

## Por que `i <- i - 1`

No c√≥digo, na p√°gina 88, dentro da instru√ß√£o `else`, por que fazer `i <- i - 1`? N√£o h√° problema te√≥rico, pois na verdade se ter√° mais r√©plicas que as 10 mil. Ent√£o, na verdade foram realizadas mais de 10 mil r√©picas de Monte-Carlo.

## Qual o m√©todo de otimia√ß√£o usado em `gamlss`?

Qual o m√©todo de otimiza√ß√£o utilizado pela fun√ß√£o `gamlss`? Seria interessante colocar nas tabelas a taxa de n√£o converg√™ncia. Isso √© √∫til, uma vez que n√£o h√° forma fechada para os estimadores de m√°xima verossimilhan√ßa. Perceber como a otimiza√ß√£o num√©rica performa na maximiza√ß√£o da fun√ß√£o de log-verossimilhan√ßa √© uma informa√ß√£o √∫til.